<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Live Transcriber — In-Browser Vosk (Free, Offline)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { --gap:12px; --border:#e5e7eb; }
    *{ box-sizing:border-box }
    body{ margin:0; font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif; }
    header{ display:flex; gap:var(--gap); align-items:center; padding:var(--gap); border-bottom:1px solid var(--border); flex-wrap:wrap; }
    header input{ flex:1 1 320px; padding:8px 10px; border:1px solid var(--border); border-radius:10px; }
    header button{ padding:8px 12px; border:1px solid var(--border); background:#111; color:#fff; border-radius:10px; cursor:pointer; }
    main{ display:grid; grid-template-columns: 1.2fr 1fr; min-height: calc(100vh - 60px); }
    #player-wrap{ padding:var(--gap); }
    #player{ width:100%; max-width:960px; aspect-ratio:16/9; background:#000; }
    #transcript{ padding:var(--gap); border-left:1px solid var(--border); overflow:auto; }
    .line{ margin:8px 0; }
    .ts{ cursor:pointer; text-decoration:underline; margin-right:6px; }
    .meta{ color:#6b7280; font-size:12px; }
    .status-dot{ display:inline-block; width:10px; height:10px; border-radius:50%; background:#9ca3af; margin-right:6px; vertical-align:middle; }
    .status-dot.live{ background:#10b981; }
    .toolbar{ display:flex; gap:8px; flex-wrap:wrap; align-items:center; }
    .note{ font-size:12px; color:#6b7280; }
  </style>
  <script src="https://www.youtube.com/iframe_api"></script>
  <!-- Vosk WASM runtime (served from your repo). Keep the relative path! -->
  <script src="./vosk/vosk.js"></script>
</head>
<body>
  <header>
    <input id="ytUrl" type="text" placeholder="Paste YouTube Live URL (optional)" />
    <button id="load">Load</button>

    <div class="toolbar">
      <button id="start">Start (pick tab/window)</button>
      <button id="stop">Stop</button>
      <button id="exportTxt">Export .txt</button>
      <button id="exportJson">Export .json</button>
    </div>

    <span class="meta"><span id="dot" class="status-dot"></span><span id="status">idle</span></span>
  </header>

  <main>
    <section id="player-wrap">
      <div id="player"></div>
      <div class="meta" style="padding:8px 0">
        Click <b>Start</b>, choose the tab/window that’s playing the livestream, and check “Share tab audio”. Runs fully in your browser — no APIs/billing.
      </div>
      <div class="note" id="modelNote">Model: not loaded</div>
    </section>
    <aside id="transcript"></aside>
  </main>

<script>
/* ====== VOSK PATHS (relative for GitHub Pages project sites) ====== */
const VOSK_BASE = "./vosk"; // where vosk.js + vosk.wasm live
const MODEL_PATH = "models/vosk-model-small-en-us-0.15"; // inside VOSK_BASE
/* ================================================================ */

let player, startedAt=0, mediaStream=null;
let audioCtx=null, srcNode=null, procNode=null;
let recognizer=null, model=null, modelLoaded=false;

function onYouTubeIframeAPIReady(){
  player = new YT.Player('player', { height:'390', width:'640', videoId:'', playerVars:{ autoplay:0, playsinline:1, modestbranding:1 }});
}
function parseYouTubeId(url){
  if (!url) return '';
  let m = url.match(/[?&]v=([A-Za-z0-9_-]{6,})/); if (m) return m[1];
  m = url.match(/youtu\.be\/([A-Za-z0-9_-]{6,})/); if (m) return m[1];
  m = url.match(/youtube\.com\/live\/([A-Za-z0-9_-]{6,})/); if (m) return m[1];
  m = url.match(/youtube\.com\/embed\/([A-Za-z0-9_-]{6,})/); if (m) return m[1];
  return '';
}
document.getElementById('load').onclick = () => {
  const url = document.getElementById('ytUrl').value.trim();
  const id = parseYouTubeId(url);
  if (id) player.loadVideoById(id);
};

function secToClock(sec){
  sec = Math.max(0, Math.floor(sec));
  const h = Math.floor(sec/3600), m = Math.floor((sec%3600)/60), s = sec%60;
  return (h? String(h).padStart(2,'0')+':' : '') + String(m).padStart(2,'0') + ':' + String(s).padStart(2,'0');
}
function addLine(text, startSec){
  if (!text) return;
  const div = document.createElement('div'); div.className = 'line';
  const a = document.createElement('span'); a.className = 'ts';
  a.textContent = '[' + secToClock(startSec) + ']';
  a.onclick = () => player?.seekTo && player.seekTo(startSec, true);
  const t = document.createElement('span'); t.textContent = ' ' + text;
  div.appendChild(a); div.appendChild(t);
  const pane = document.getElementById('transcript');
  pane.appendChild(div); pane.scrollTop = pane.scrollHeight;
}
function setStatus(msg, live=false){
  document.getElementById('status').textContent = msg;
  document.getElementById('dot').classList.toggle('live', !!live);
  console.log('[status]', msg);
}
function setModelNote(msg){
  document.getElementById('modelNote').textContent = msg;
}

/* ---------- Downsample to 16 kHz Int16 for Vosk ---------- */
function downsampleTo16k(float32Array, inSampleRate){
  const outSampleRate = 16000;
  if (inSampleRate === outSampleRate) {
    const out = new Int16Array(float32Array.length);
    for (let i=0;i<float32Array.length;i++){
      let s = Math.max(-1, Math.min(1, float32Array[i]));
      out[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return out;
  }
  const ratio = inSampleRate / outSampleRate;
  const newLen = Math.round(float32Array.length / ratio);
  const out = new Int16Array(newLen);
  for (let i=0;i<newLen;i++){
    const idx = i*ratio;
    const i0 = Math.floor(idx), i1 = Math.min(i0+1, float32Array.length-1);
    const frac = idx - i0;
    const s = float32Array[i0]*(1-frac) + float32Array[i1]*frac;
    let v = Math.max(-1, Math.min(1, s));
    out[i] = v < 0 ? v*0x8000 : v*0x7FFF;
  }
  return out;
}

/* ------------------- Load Vosk (WASM + Model) ------------------- */
async function ensureVoskLoaded(){
  if (modelLoaded) return true;
  if (!window.Vosk) { alert("Vosk runtime not found. Make sure ./vosk/vosk.js is served."); return false; }

  setModelNote("Loading Vosk WASM… (first load 5–20s)");
  Vosk.setModuleBase(VOSK_BASE + "/"); // vosk.wasm sits here
  model = await Vosk.createModel(VOSK_BASE + "/" + MODEL_PATH);
  recognizer = new model.KaldiRecognizer(16000); // mono 16k
  modelLoaded = true;
  setModelNote("Model loaded ✔ (small EN)");
  return true;
}

/* ---------------- Start/Stop ---------------- */
document.getElementById('start').onclick = async () => {
  try{
    if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
      console.warn('Screen/tab capture needs HTTPS. Use GitHub Pages or localhost.');
    }

    // Ensure model is loaded
    const ok = await ensureVoskLoaded();
    if (!ok) return;

    // Request VIDEO + AUDIO; audio-only often fails
    const ms = await navigator.mediaDevices.getDisplayMedia({
      video: true,
      audio: { echoCancellation:false, noiseSuppression:false, autoGainControl:false }
    });
    // Stop video track immediately; we only need audio
    const vt = ms.getVideoTracks()[0]; if (vt) vt.stop();
    const at = ms.getAudioTracks()[0];
    if (!at) { alert('No audio captured. Pick the tab with sound and check “Share tab audio”.'); return; }
    mediaStream = ms;

    // WebAudio pipeline: MediaStream → ScriptProcessor → downsample → recognizer
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    srcNode = audioCtx.createMediaStreamSource(mediaStream);

    const bufSize = 4096; // tweak 2048..8192 for CPU/latency tradeoff
    procNode = audioCtx.createScriptProcessor(bufSize, 1, 1);
    procNode.onaudioprocess = () => {
      const input = new Float32Array(procNode.bufferSize);
      // Pull latest buffer
      const chData = procNode.context.createBuffer(1, procNode.bufferSize, audioCtx.sampleRate);
      // NOTE: ScriptProcessor gives input via event in some browsers; fallback:
      // If your browser provides e.inputBuffer in handler, you can use that instead.
    };

    // Proper handler with input buffer:
    procNode.onaudioprocess = (e) => {
      const ch0 = e.inputBuffer.getChannelData(0); // Float32 -1..1
      const pcm16 = downsampleTo16k(ch0, audioCtx.sampleRate);
      recognizer.acceptWaveform(pcm16);
      const r = recognizer.result(); // “final-ish” result chunks
      if (r && r.text) {
        const secs = Math.floor((Date.now() - startedAt)/1000);
        addLine(r.text, Math.max(0, secs - 1));
      } else {
        // Optional: show partials
        // const p = recognizer.partialResult();
        // if (p && p.partial) { /* show lightweight partials if you want */ }
      }
    };

    srcNode.connect(procNode);
    procNode.connect(audioCtx.destination); // keep node alive; audio is effectively silent

    startedAt = Date.now();
    setStatus('listening (local Vosk)…', true);
  }catch(err){
    setStatus('error: ' + (err?.message || String(err)), false);
  }
};

document.getElementById('stop').onclick = () => {
  try { procNode && procNode.disconnect(); } catch {}
  try { srcNode && srcNode.disconnect(); } catch {}
  try { audioCtx && audioCtx.close(); } catch {}
  try { mediaStream && mediaStream.getTracks().forEach(t => t.stop()); } catch {}
  setStatus('stopped', false);
};

/* ----------------- Exports ----------------- */
document.getElementById('exportTxt').onclick = () => {
  const lines = [...document.querySelectorAll('.line')].map(div => div.textContent.trim());
  const blob = new Blob([lines.join('\n')], {type:'text/plain'});
  const a = document.createElement('a'); a.href = URL.createObjectURL(blob);
  a.download = 'transcript.txt'; a.click(); URL.revokeObjectURL(a.href);
};
document.getElementById('exportJson').onclick = () => {
  const out = [...document.querySelectorAll('.line')].map(div => {
    const ts = div.querySelector('.ts')?.textContent?.replace(/\[|\]/g,'') || '00:00';
    const text = div.textContent.replace(/\[.*?\]\s*/, '').trim();
    return { ts, text };
  });
  const a = document.createElement('a');
  a.href = URL.createObjectURL(new Blob([JSON.stringify({ lines: out }, null, 2)], {type:'application/json'}));
  a.download = 'transcript.json'; a.click(); URL.revokeObjectURL(a.href);
};
</script>
</body>
</html>
